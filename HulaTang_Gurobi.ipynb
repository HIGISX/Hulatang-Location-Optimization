{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooperative-Competitive Maximum Coverage Location Problem  solved by Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T12:55:20.211248Z",
     "start_time": "2025-09-09T12:55:20.207245Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T12:55:20.289477Z",
     "start_time": "2025-09-09T12:55:20.259816Z"
    }
   },
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import math\n",
    "\n",
    "\n",
    "def solve_hulatang_location_model(demand_points, candidate_sites, existing_stores, p, parameters, distance_matrix, allowed_pairs=None):\n",
    "    \"\"\"\n",
    "    Solve the cooperative–competitive Hulatang location model with Gurobi (supports service-radius constraints).\n",
    "\n",
    "    Args:\n",
    "        demand_points (dict): demand dictionary {demand_id: market_value_V}\n",
    "        candidate_sites (dict): candidate dictionary {candidate_id: {'coords': (x, y), 'rent': rent_F, 'norm_coords': (nx, ny)}}\n",
    "        existing_stores (dict): existing store dictionary {store_id: {'coords': (x, y), 'Ak': score_A, 'Pk': score_P, 'norm_coords': (nx, ny)}}\n",
    "        p (int): number of new stores to open\n",
    "        parameters (dict): model params {'w1', 'w2', 'w3', 'w4', 'delta_agg', 'delta_comp'}\n",
    "        distance_matrix (dict): candidate-to-existing distance matrix {(candidate_id, store_id): distance_norm}\n",
    "        allowed_pairs (set[tuple]|list[tuple]|None): allowed (i, j) service pairs (generated by radius using normalized coords).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (selected_sites, objective_value, covered_demand, total_demand, coverage_rate)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # --- 1. Preprocessing: compute agglomeration benefit (B_j) and competition cost (C_j) for each candidate ---\n",
    "    B, C = {}, {}\n",
    "    delta_agg_sq = parameters['delta_agg'] ** 2\n",
    "    delta_comp_sq = parameters['delta_comp'] ** 2\n",
    "\n",
    "    for j in candidate_sites.keys():\n",
    "        total_agglomeration_benefit = 0\n",
    "        total_competition_cost = 0\n",
    "        for k, store_data in existing_stores.items():\n",
    "            dist_sq = distance_matrix[j, k] ** 2\n",
    "            total_agglomeration_benefit += store_data['Ak'] * math.exp(-dist_sq / delta_agg_sq)\n",
    "            total_competition_cost += store_data['Pk'] * math.exp(-dist_sq / delta_comp_sq)\n",
    "        B[j] = total_agglomeration_benefit\n",
    "        C[j] = total_competition_cost\n",
    "\n",
    "    # --- 2. Gurobi model construction ---\n",
    "    model = gp.Model(\"Hulatang_Location_Optimization\")\n",
    "    model.setParam('OutputFlag', False) # silence solver log\n",
    "\n",
    "\n",
    "    I = list(demand_points.keys())  # demand index set\n",
    "    J = list(candidate_sites.keys())  # candidate index set\n",
    "\n",
    "    # Decision variable X\n",
    "    X = model.addVars(J, vtype=GRB.BINARY, name=\"X\")\n",
    "\n",
    "    # Decision variable Y: if allowed_pairs provided, create only for those (i, j)\n",
    "    if allowed_pairs is not None:\n",
    "        allowed_pairs = list(allowed_pairs)\n",
    "        Y = model.addVars(allowed_pairs, vtype=GRB.BINARY, name=\"Y\")\n",
    "        # Precompute index for later aggregation\n",
    "        from collections import defaultdict\n",
    "        J_by_i = defaultdict(list)\n",
    "        for (i, j) in allowed_pairs:\n",
    "            J_by_i[i].append(j)\n",
    "    else:\n",
    "        Y = model.addVars(I, J, vtype=GRB.BINARY, name=\"Y\")\n",
    "        J_by_i = None\n",
    "\n",
    "    # Objective\n",
    "    if allowed_pairs is not None:\n",
    "        coverage_term = gp.quicksum(demand_points[i] * Y[i, j] for (i, j) in allowed_pairs)\n",
    "    else:\n",
    "        coverage_term = gp.quicksum(demand_points[i] * Y[i, j] for i in I for j in J)\n",
    "\n",
    "    objective = (\n",
    "        parameters['w1'] * coverage_term +\n",
    "        parameters['w3'] * gp.quicksum(B[j] * X[j] for j in J) -\n",
    "        parameters['w4'] * gp.quicksum(C[j] * X[j] for j in J) -\n",
    "        parameters['w2'] * gp.quicksum(candidate_sites[j]['rent'] * X[j] for j in J)\n",
    "    )\n",
    "    model.setObjective(objective, GRB.MAXIMIZE)\n",
    "\n",
    "    # Constraint: number of opened stores\n",
    "    model.addConstr(gp.quicksum(X[j] for j in J) == p, name=\"Total_Stores_Constraint\")\n",
    "\n",
    "    # Constraint: each demand i can be served by at most one j\n",
    "    if allowed_pairs is not None:\n",
    "        for i in I:\n",
    "            js = J_by_i.get(i, [])\n",
    "            if len(js) > 0:\n",
    "                model.addConstr(gp.quicksum(Y[i, j] for j in js) <= 1, name=f\"Demand_Service_Constraint_{i}\")\n",
    "            else:\n",
    "                # If no candidate can serve i under the radius, skip (equivalent to 0 <= 1)\n",
    "                pass\n",
    "    else:\n",
    "        for i in I:\n",
    "            model.addConstr(gp.quicksum(Y[i, j] for j in J) <= 1, name=f\"Demand_Service_Constraint_{i}\")\n",
    "\n",
    "    # Constraint: linking — can only serve if the facility is opened\n",
    "    if allowed_pairs is not None:\n",
    "        for (i, j) in allowed_pairs:\n",
    "            model.addConstr(Y[i, j] <= X[j], name=f\"Linking_Constraint_{i}_{j}\")\n",
    "    else:\n",
    "        for i in I:\n",
    "            for j in J:\n",
    "                model.addConstr(Y[i, j] <= X[j], name=f\"Linking_Constraint_{i}_{j}\")\n",
    "\n",
    "    # Solve\n",
    "    model.optimize()\n",
    "\n",
    "    # Results\n",
    "    selected_sites = []\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        objective_value = model.ObjVal\n",
    "        for j in J:\n",
    "            if X[j].X > 0.5:\n",
    "                selected_sites.append(j)\n",
    "    else:\n",
    "        objective_value = None\n",
    "        print(\"Model infeasible or not optimal.\")\n",
    "\n",
    "    # Coverage statistics: if allowed_pairs is used, check if a built store can serve i\n",
    "    total_demand = float(sum(demand_points.values()))\n",
    "    covered_demand = 0.0\n",
    "    if allowed_pairs is not None and objective_value is not None:\n",
    "        built = set(selected_sites)\n",
    "        from collections import defaultdict\n",
    "        js_of_i = defaultdict(list)\n",
    "        for (i, j) in allowed_pairs:\n",
    "            if j in built:\n",
    "                js_of_i[i].append(j)\n",
    "        for i, js in js_of_i.items():\n",
    "            # If any built j can serve i, mark i as covered\n",
    "            if len(js) > 0:\n",
    "                covered_demand += float(demand_points[i])\n",
    "    coverage_rate = (covered_demand / total_demand) if total_demand > 0 else 0.0\n",
    "\n",
    "    # Component metrics (weighted as in the objective)\n",
    "    sum_B_selected = sum(B[j] for j in selected_sites)\n",
    "    sum_C_selected = sum(C[j] for j in selected_sites)\n",
    "    sum_rent_selected = sum(candidate_sites[j]['rent'] for j in selected_sites)\n",
    "\n",
    "    metrics = {\n",
    "        'market_benefit': parameters['w1'] * covered_demand,\n",
    "        'agglomeration_benefit': parameters['w3'] * sum_B_selected,\n",
    "        'competition_cost': parameters['w4'] * sum_C_selected,  # objective subtracts this term\n",
    "        'rent_cost': parameters['w2'] * sum_rent_selected,      # objective subtracts this term\n",
    "        'avg_rent': (sum_rent_selected / len(selected_sites)) if len(selected_sites) > 0 else 0.0,\n",
    "        'sum_rent': sum_rent_selected,\n",
    "        'sum_B': sum_B_selected,\n",
    "        'sum_C': sum_C_selected,\n",
    "    }\n",
    "\n",
    "    return selected_sites, objective_value, covered_demand, total_demand, coverage_rate, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T12:55:20.644443Z",
     "start_time": "2025-09-09T12:55:20.629493Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def render_scale_bar(ax, x, y, segments=2, height=0.01, seg_length=2000, unit='m', linewidth=1.):\n",
    "    unit_scale_factor = {\n",
    "        'm': 1,\n",
    "        'km': 1000,\n",
    "        'meters': 1,\n",
    "        'kilometers': 1000,\n",
    "        'miles': 1609.34,\n",
    "        'mi': 1609.34,\n",
    "        'ft': 0.3,\n",
    "        }\n",
    "    x_lim = ax.get_xlim()\n",
    "    y_lim = ax.get_ylim()\n",
    "\n",
    "    x_per_unit = 1. / (x_lim[1] - x_lim[0])\n",
    "    y_per_unit = 1. / (y_lim[1] - y_lim[0])\n",
    "\n",
    "    # base for ticks (0, 1)\n",
    "    x_base = [x + seg_length * unit_scale_factor[unit] * x_per_unit * i for i in range(0, segments + 1)]\n",
    "    ax.axhline(y_lim[0] + y / y_per_unit, x_base[0], x_base[-1], c='black')\n",
    "    y_base = [y, y + height]\n",
    "    for i in range(segments + 1):\n",
    "        ax.axvline(x_lim[0] + x_base[i] / x_per_unit, y, y + height, c='black')\n",
    "        xy = (x_lim[0] + x_base[i] / x_per_unit, y_lim[0] + (y - 0.015) / y_per_unit)  # data_coords\n",
    "        ax.text(xy[0], xy[1], s='{}'.format(int(seg_length * i)), horizontalalignment='center', verticalalignment='center')\n",
    "    ax.text(x_lim[0] + (x_base[-1] + 0.02) / x_per_unit, y_lim[0] + (y - 0.015) / y_per_unit,\n",
    "            s=unit, horizontalalignment='left',\n",
    "            verticalalignment='center')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def render_north_arrow(ax, x, y, size, ratio = 1):\n",
    "    path = [(0, 1), (-ratio, -1), (0, -0.5), (ratio, -1), (0, 1)]\n",
    "    path = [(i[0] * size + x, i[1] * size + y) for i in path]\n",
    "    arrow = plt.Polygon(path, color='black', transform=ax.transAxes)\n",
    "    ax.add_patch(arrow)\n",
    "    ax.text(x, y-size*2, s = 'N', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Read HuLaTang data and build dictionaries ===\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "base_dir = \"data/HuLaTang\"\n",
    "demand_shp_path = os.path.join(base_dir, \"Deman_Point.shp\")\n",
    "candidate_csv_path = os.path.join(base_dir, \"Candidate_Point.csv\")\n",
    "existing_csv_path = os.path.join(base_dir, \"Hulatang.csv\")\n",
    "\n",
    "# 1) Read demand points (shp). Market demand comes from column All_pop\n",
    "ls_hlt = gpd.read_file(demand_shp_path)\n",
    "if not ls_hlt.geom_type.isin([\"Point\"]).all():\n",
    "    # If polygons/lines, use centroids\n",
    "    ls_hlt = ls_hlt.copy()\n",
    "    ls_hlt[\"geometry\"] = ls_hlt.geometry.centroid\n",
    "ls_hlt[\"X\"] = ls_hlt.geometry.x\n",
    "ls_hlt[\"Y\"] = ls_hlt.geometry.y\n",
    "\n",
    "# Case-insensitive detection of All_pop\n",
    "all_pop_col = None\n",
    "for c in ls_hlt.columns:\n",
    "    if c.lower() == \"all_pop\":\n",
    "        all_pop_col = c\n",
    "        break\n",
    "if all_pop_col is None:\n",
    "    raise ValueError(\"Column 'All_pop' not found in demand shapefile; please check field names.\")\n",
    "\n",
    "# Demand ids: prefer FID/Id, otherwise row index\n",
    "if \"FID\" in ls_hlt.columns:\n",
    "    demand_ids = ls_hlt[\"FID\"].astype(int).tolist()\n",
    "elif \"Id\" in ls_hlt.columns:\n",
    "    demand_ids = ls_hlt[\"Id\"].astype(int).tolist()\n",
    "else:\n",
    "    demand_ids = list(range(len(ls_hlt)))\n",
    "\n",
    "# Build demand_points: {demand_id: All_pop}\n",
    "demand_points = {demand_ids[i]: float(ls_hlt.iloc[i][all_pop_col]) for i in range(len(ls_hlt))}\n",
    "\n",
    "# 2) Read candidates (csv): rent from ZUJIN/Zujin; coordinates from point_x_1/point_y_1\n",
    "encodings = [\"utf-8-sig\", \"gbk\", \"utf-8\"]\n",
    "for enc in encodings:\n",
    "    try:\n",
    "        cand_df = pd.read_csv(candidate_csv_path, encoding=enc)\n",
    "        break\n",
    "    except Exception:\n",
    "        cand_df = None\n",
    "if cand_df is None:\n",
    "    raise RuntimeError(\"Failed to read Candidate_Point.csv; please check file and encoding.\")\n",
    "\n",
    "# Coordinate columns compatibility\n",
    "x_col = None\n",
    "y_col = None\n",
    "for c in cand_df.columns:\n",
    "    cl = c.lower()\n",
    "    if cl in (\"point_x_1\", \"x\", \"point_x\"):\n",
    "        x_col = c if x_col is None else x_col\n",
    "    if cl in (\"point_y_1\", \"y\", \"point_y\"):\n",
    "        y_col = c if y_col is None else y_col\n",
    "if x_col is None or y_col is None:\n",
    "    raise ValueError(\"Candidate csv is missing coordinate columns (point_x_1/point_y_1 or X/Y).\")\n",
    "\n",
    "# Rent column compatibility\n",
    "rent_col = None\n",
    "for c in cand_df.columns:\n",
    "    if c.lower() in (\"zujin\", \"租金\", \"rent\"):\n",
    "        rent_col = c\n",
    "        break\n",
    "if rent_col is None:\n",
    "    raise ValueError(\"Candidate csv is missing rent column (ZUJIN/租金/rent).\")\n",
    "\n",
    "# Normalize index\n",
    "cand_df = cand_df.reset_index(drop=True)\n",
    "J_ids = list(range(len(cand_df)))\n",
    "\n",
    "# Build candidate_sites: {j: {coords: (x,y), rent: F_j}}\n",
    "candidate_sites = {\n",
    "    j: {\n",
    "        \"coords\": (float(cand_df.loc[j, x_col]), float(cand_df.loc[j, y_col])),\n",
    "        \"rent\": float(cand_df.loc[j, rent_col])\n",
    "    }\n",
    "    for j in J_ids\n",
    "}\n",
    "\n",
    "# 3) Read existing stores (csv), with Brand, Ak, Pk and coordinates X, Y\n",
    "for enc in encodings:\n",
    "    try:\n",
    "        stores_df = pd.read_csv(existing_csv_path, encoding=enc)\n",
    "        break\n",
    "    except Exception:\n",
    "        stores_df = None\n",
    "if stores_df is None:\n",
    "    raise RuntimeError(\"Failed to read Hulatang.csv; please check file and encoding.\")\n",
    "\n",
    "# Column compatibility\n",
    "store_x_col = None\n",
    "store_y_col = None\n",
    "for c in stores_df.columns:\n",
    "    if c.lower() == \"x\":\n",
    "        store_x_col = c\n",
    "    if c.lower() == \"y\":\n",
    "        store_y_col = c\n",
    "if store_x_col is None or store_y_col is None:\n",
    "    # Fallback: some tables use POINT_X/POINT_Y\n",
    "    for c in stores_df.columns:\n",
    "        if c.lower() in (\"point_x\", \"pointx\"):\n",
    "            store_x_col = c\n",
    "        if c.lower() in (\"point_y\", \"pointy\"):\n",
    "            store_y_col = c\n",
    "if store_x_col is None or store_y_col is None:\n",
    "    raise ValueError(\"Store csv is missing coordinate columns (X/Y or POINT_X/POINT_Y).\")\n",
    "\n",
    "Ak_col = None\n",
    "Pk_col = None\n",
    "for c in stores_df.columns:\n",
    "    if c.lower() == \"ak\":\n",
    "        Ak_col = c\n",
    "    if c.lower() == \"pk\":\n",
    "        Pk_col = c\n",
    "if Ak_col is None or Pk_col is None:\n",
    "    raise ValueError(\"Store csv is missing Ak or Pk columns.\")\n",
    "\n",
    "stores_df = stores_df.reset_index(drop=True)\n",
    "K_ids = list(range(len(stores_df)))\n",
    "\n",
    "# Build existing_stores: {k: {coords: (x,y), Ak: , Pk: , Brand: }}\n",
    "existing_stores = {\n",
    "    k: {\n",
    "        \"coords\": (float(stores_df.loc[k, store_x_col]), float(stores_df.loc[k, store_y_col])),\n",
    "        \"Ak\": float(stores_df.loc[k, Ak_col]),\n",
    "        \"Pk\": float(stores_df.loc[k, Pk_col]),\n",
    "        \"Brand\": str(stores_df.loc[k, \"Brand\"]) if \"Brand\" in stores_df.columns else \"\"\n",
    "    }\n",
    "    for k in K_ids\n",
    "}\n",
    "\n",
    "print(f\"Demand: {len(demand_points)}, Candidates: {len(candidate_sites)}, Existing stores: {len(existing_stores)}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Coordinate normalization (unified for candidates and existing stores) ===\n",
    "# Extract raw coordinates from candidate_sites / existing_stores\n",
    "cand_xy = np.array([candidate_sites[j][\"coords\"] for j in sorted(candidate_sites.keys())], dtype=float)\n",
    "store_xy = np.array([existing_stores[k][\"coords\"] for k in sorted(existing_stores.keys())], dtype=float)\n",
    "all_xy = np.vstack([cand_xy, store_xy])\n",
    "\n",
    "# Compute scale S and normalize to [0, 1]\n",
    "x = all_xy[:, 0]\n",
    "y = all_xy[:, 1]\n",
    "min_x, max_x = x.min(), x.max()\n",
    "min_y, max_y = y.min(), y.max()\n",
    "S = max(max_x - min_x, max_y - min_y)\n",
    "Nx = (x - min_x) / S\n",
    "Ny = (y - min_y) / S\n",
    "norm_xy = np.vstack([Nx, Ny]).T\n",
    "\n",
    "# Backfill norm_coords for candidate_sites / existing_stores\n",
    "J_sorted = sorted(candidate_sites.keys())\n",
    "K_sorted = sorted(existing_stores.keys())\n",
    "for idx, j in enumerate(J_sorted):\n",
    "    candidate_sites[j][\"norm_coords\"] = (float(norm_xy[idx, 0]), float(norm_xy[idx, 1]))\n",
    "for idx, k in enumerate(K_sorted):\n",
    "    existing_stores[k][\"norm_coords\"] = (float(norm_xy[len(J_sorted)+idx, 0]), float(norm_xy[len(J_sorted)+idx, 1]))\n",
    "\n",
    "print(f\"Normalization done. Scale S = {S:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T12:55:23.621325Z",
     "start_time": "2025-09-09T12:55:22.475882Z"
    }
   },
   "outputs": [],
   "source": [
    "# === Distance matrix (using normalized coordinates) ===\n",
    "import numpy as np\n",
    "\n",
    "J_sorted = sorted(candidate_sites.keys())\n",
    "K_sorted = sorted(existing_stores.keys())\n",
    "cand_norm = np.array([candidate_sites[j][\"norm_coords\"] for j in J_sorted], dtype=float)\n",
    "store_norm = np.array([existing_stores[k][\"norm_coords\"] for k in K_sorted], dtype=float)\n",
    "cd = cand_norm[:, None, :] - store_norm[None, :, :]\n",
    "dists_norm = np.sqrt((cd ** 2).sum(axis=2))\n",
    "\n",
    "distance_matrix = {}\n",
    "for jj, j in enumerate(J_sorted):\n",
    "    for kk, k in enumerate(K_sorted):\n",
    "        distance_matrix[(j, k)] = float(dists_norm[jj, kk])\n",
    "\n",
    "print(f\"Distance matrix size (normalized): {len(J_sorted)} x {len(K_sorted)} built\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T12:55:23.933470Z",
     "start_time": "2025-09-09T12:55:23.847065Z"
    }
   },
   "outputs": [],
   "source": [
    "# === Demand normalization and service-radius filtering (R=1000m) ===\n",
    "# 1) Original demand coordinates\n",
    "demand_xy = ls_hlt[[\"X\", \"Y\"]].to_numpy(float)\n",
    "\n",
    "# 2) Normalize using the same min/max and S as candidates/stores (joint range)\n",
    "cand_xy = np.array([candidate_sites[j][\"coords\"] for j in sorted(candidate_sites.keys())], dtype=float)\n",
    "store_xy = np.array([existing_stores[k][\"coords\"] for k in sorted(existing_stores.keys())], dtype=float)\n",
    "all_xy_cs = np.vstack([cand_xy, store_xy])\n",
    "min_x_cs, max_x_cs = all_xy_cs[:, 0].min(), all_xy_cs[:, 0].max()\n",
    "min_y_cs, max_y_cs = all_xy_cs[:, 1].min(), all_xy_cs[:, 1].max()\n",
    "S = max(max_x_cs - min_x_cs, max_y_cs - min_y_cs)  # same S as normalization step\n",
    "\n",
    "Nx_d = (demand_xy[:, 0] - min_x_cs) / S\n",
    "Ny_d = (demand_xy[:, 1] - min_y_cs) / S\n",
    "demand_norm = np.vstack([Nx_d, Ny_d]).T\n",
    "\n",
    "# 3) Radius filter\n",
    "R_m = 1000.0\n",
    "R_norm = R_m / S\n",
    "J_sorted = sorted(candidate_sites.keys())\n",
    "\n",
    "cand_norm = np.array([candidate_sites[j]['norm_coords'] for j in J_sorted], dtype=float)\n",
    "\n",
    "# Demand id mapping (consistent with demand_points keys)\n",
    "if \"FID\" in ls_hlt.columns:\n",
    "    id_series = ls_hlt[\"FID\"].astype(int)\n",
    "elif \"Id\" in ls_hlt.columns:\n",
    "    id_series = ls_hlt[\"Id\"].astype(int)\n",
    "else:\n",
    "    id_series = pd.Series(range(len(ls_hlt)))\n",
    "\n",
    "allowed_pairs = []\n",
    "for j_idx, j in enumerate(J_sorted):\n",
    "    diff = demand_norm - cand_norm[j_idx]\n",
    "    d = np.sqrt((diff ** 2).sum(axis=1))\n",
    "    for ridx in np.where(d <= R_norm)[0]:\n",
    "        i = int(id_series.iloc[ridx])\n",
    "        allowed_pairs.append((i, j))\n",
    "\n",
    "allowed_pairs = set(allowed_pairs)\n",
    "print(f\"Service radius R = {R_m} m (normalized {R_norm:.8f}), allowed pairs: {len(allowed_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T12:55:26.043313Z",
     "start_time": "2025-09-09T12:55:24.133785Z"
    }
   },
   "outputs": [],
   "source": [
    "# === Run the model (δ uses normalized scale) ===\n",
    "params = {\n",
    "    'w1': 0.4,\n",
    "    'w3': 0.1,\n",
    "    'w2': 0.25,\n",
    "    'w4': 0.25,\n",
    "    'delta_agg': 700.0 / S,\n",
    "    'delta_comp': 150.0 / S,\n",
    "}\n",
    "\n",
    "p_new = 20\n",
    "\n",
    "selected_sites, objective_value, covered_demand, total_demand, coverage_rate, metrics = solve_hulatang_location_model(\n",
    "    demand_points=demand_points,\n",
    "    candidate_sites=candidate_sites,\n",
    "    existing_stores=existing_stores,\n",
    "    p=p_new,\n",
    "    parameters=params,\n",
    "    distance_matrix=distance_matrix,\n",
    "    allowed_pairs=allowed_pairs\n",
    ")\n",
    "print(f\"Optimal objective: {objective_value:.0f}\")\n",
    "print(f\"Market coverage benefit: {metrics['market_benefit']:.0f}\")\n",
    "print(f\"Agglomeration benefit: {metrics['agglomeration_benefit']:.0f}\")\n",
    "print(f\"Competition cost: {-metrics['competition_cost']:.0f}\")  # subtracted in objective\n",
    "print(f\"Rent cost: {-metrics['rent_cost']:.0f}\")                 # subtracted in objective\n",
    "print(f\"Average rent per store: {metrics['avg_rent']:.0f}\")\n",
    "print(f\"Covered demand: {covered_demand:.0f} / Total demand: {total_demand:.0f}\")\n",
    "print(f\"Coverage rate: {coverage_rate:.2%}\")\n",
    "\n",
    "# Inspect selected sites\n",
    "if len(selected_sites) > 0:\n",
    "    sel_df = cand_df.loc[selected_sites, [x_col, y_col, rent_col]].copy()\n",
    "    sel_df[\"candidate_id\"] = selected_sites\n",
    "    display(sel_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T12:55:26.338242Z",
     "start_time": "2025-09-09T12:55:26.326448Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T12:55:27.019735Z",
     "start_time": "2025-09-09T12:55:26.620567Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 18))\n",
    "\n",
    "try:\n",
    "    cmap = plt.cm.Blues\n",
    "    new_cmap = colors.ListedColormap(cmap(np.linspace(0.15, 1, 256)))\n",
    "    ls_hlt.plot(ax=ax, column=ls_hlt[all_pop_col], k=5, markersize=15, cmap=new_cmap, label='Market (All_pop)')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if len(selected_sites) > 0:\n",
    "    opt_sites = cand_df.loc[selected_sites]\n",
    "    ax.scatter(opt_sites[x_col], opt_sites[y_col], c='C1', marker='+', s=100, label='Selected Sites')\n",
    "\n",
    "ax.axis('scaled')\n",
    "ax.tick_params(axis='both', left=False, top=False, right=False,\n",
    "               bottom=False, labelleft=False, labeltop=False,\n",
    "               labelright=False, labelbottom=False)\n",
    "ax.set_title(\"Optimized Site Selection (Normalized distances)\", fontsize=20)\n",
    "render_scale_bar(ax=ax, x=0.05, y=0.05)\n",
    "render_north_arrow(ax=ax, x=0.95, y=0.95, size=0.01, ratio=0.7)\n",
    "ax.legend(loc='lower right', markerscale=10)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import patheffects as pe\n",
    "\n",
    "def plot_result_pretty(ls, opt_sites, radius_m=2000, roads_path=\"data/HuLaTang/Road_Network.shp\",\n",
    "                       demand_gridsize=60, demand_cmap=\"magma\", roads_color=\"#9e9e9e\", roads_alpha=0.35,\n",
    "                       norm_mode=\"log\", vmin_q=0.10, vmax_q=0.995, gamma=0.6, reduce=\"sum\",\n",
    "                       overlay_points=True, overlay_points_size=6, overlay_points_alpha=0.28,\n",
    "                       overlay_hex_grid=False, hex_grid_color=\"#222222\", hex_grid_alpha=0.18, hex_grid_lw=0.25,\n",
    "                       circle_style=\"ring\", show_heat=True, show_colorbar=False, lang=\"zh\", title=None):\n",
    "    \"\"\"\n",
    "    Publication-quality plotting for site selection: demand heat (hexbin) + roads + facilities + service circles.\n",
    "\n",
    "    Args:\n",
    "        ls (GeoDataFrame): demand points containing POINT_X/POINT_Y or X/Y and optionally All_pop.\n",
    "        opt_sites (DataFrame): selected rows with x/y columns (point_x_1/POINT_X...).\n",
    "        radius_m (float): service radius (same units as coordinates).\n",
    "        roads_path (str): path to road shapefile.\n",
    "        demand_gridsize (int): hexbin grid size.\n",
    "        demand_cmap (str): colormap for demand heat.\n",
    "        roads_color (str): road color.\n",
    "        roads_alpha (float): road alpha.\n",
    "        norm_mode (str): 'log' | 'power' | 'linear'.\n",
    "        vmin_q, vmax_q (float): demand quantile clipping, for display only.\n",
    "        gamma (float): gamma for PowerNorm.\n",
    "        reduce (str): 'sum' or 'mean' for hexbin aggregation.\n",
    "        overlay_points (bool): overlay demand points.\n",
    "        circle_style (str): 'fill' | 'ring' service circle style.\n",
    "        show_colorbar (bool): whether to display colorbar.\n",
    "        lang (str): 'zh' or 'en' for labels.\n",
    "        title (str|None): custom title.\n",
    "    \"\"\"\n",
    "    L = {\n",
    "        'zh': {\n",
    "            'road': '道路网络', 'demand': '需求点', 'selected': '新建门店', 'current': '现有门店',\n",
    "            'title': '选址结果与需求强度', 'subtitle': lambda n, r: f\"门店数：{n}  半径：{r} m\"\n",
    "        },\n",
    "        'en': {\n",
    "            'road': 'Road network', 'demand': 'Demand points', 'selected': 'Selected facilities', 'current': 'Current sites',\n",
    "            'title': 'Optimized Facilities with Demand Heat', 'subtitle': lambda n, r: f\"Facilities: {n}  Radius: {r} m\"\n",
    "        }\n",
    "    }\n",
    "    LL = L.get(lang, L['zh'])\n",
    "\n",
    "    pop_col = None\n",
    "    if 'speed_pct_freeflow_rev' in ls.columns:\n",
    "        pop_col = 'speed_pct_freeflow_rev'\n",
    "    else:\n",
    "        for c in ls.columns:\n",
    "            if str(c).lower() == 'all_pop':\n",
    "                pop_col = c\n",
    "                break\n",
    "    if 'X' in ls.columns and 'Y' in ls.columns:\n",
    "        dx, dy = 'X', 'Y'\n",
    "    else:\n",
    "        dx, dy = 'POINT_X', 'POINT_Y'\n",
    "    if dx not in ls.columns or dy not in ls.columns:\n",
    "        raise ValueError(\"ls must contain POINT_X/POINT_Y or X/Y columns.\")\n",
    "\n",
    "    def pick_xy_cols(df):\n",
    "        x_col = None\n",
    "        y_col = None\n",
    "        for c in df.columns:\n",
    "            cl = str(c).lower()\n",
    "            if cl in ('point_x_1', 'x', 'point_x', 'pointx') and x_col is None:\n",
    "                x_col = c\n",
    "            if cl in ('point_y_1', 'y', 'point_y', 'pointy') and y_col is None:\n",
    "                y_col = c\n",
    "        if x_col is None and 'POINT_X' in df.columns: x_col = 'POINT_X'\n",
    "        if y_col is None and 'POINT_Y' in df.columns: y_col = 'POINT_Y'\n",
    "        if x_col is None or y_col is None:\n",
    "            raise ValueError('opt_sites missing XY columns (point_x_1/point_y_1 or X/Y or POINT_X/POINT_Y).')\n",
    "        return x_col, y_col\n",
    "\n",
    "    x_col, y_col = pick_xy_cols(opt_sites)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 16))\n",
    "\n",
    "    if isinstance(roads_path, str) and os.path.exists(roads_path):\n",
    "        try:\n",
    "            roads = gpd.read_file(roads_path)\n",
    "            try:\n",
    "                roads.plot(ax=ax, color=roads_color, linewidth=0.4, alpha=roads_alpha, zorder=1, label=LL['road'])\n",
    "            except Exception:\n",
    "                pass\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        if show_heat:\n",
    "            values = ls[pop_col].to_numpy() if pop_col is not None else None\n",
    "            if values is not None:\n",
    "                vmin = float(np.quantile(values, vmin_q)) if 0 <= vmin_q < 1 else None\n",
    "                vmax = float(np.quantile(values, vmax_q)) if 0 < vmax_q <= 1 else None\n",
    "                if vmin is not None and vmax is not None and vmax > vmin:\n",
    "                    values_clipped = np.clip(values, vmin, vmax)\n",
    "                else:\n",
    "                    values_clipped = values\n",
    "                if norm_mode == 'log':\n",
    "                    from matplotlib.colors import LogNorm\n",
    "                    norm = LogNorm(vmin=max(values_clipped.min(), 1e-6), vmax=values_clipped.max())\n",
    "                elif norm_mode == 'power':\n",
    "                    from matplotlib.colors import PowerNorm\n",
    "                    norm = PowerNorm(gamma=gamma, vmin=values_clipped.min(), vmax=values_clipped.max())\n",
    "                else:\n",
    "                    norm = None\n",
    "            else:\n",
    "                values_clipped = None\n",
    "                norm = None\n",
    "\n",
    "            reducer = np.sum if reduce == 'sum' else np.mean\n",
    "            hb = ax.hexbin(ls[dx].to_numpy(), ls[dy].to_numpy(),\n",
    "                           C=values_clipped,\n",
    "                           reduce_C_function=reducer if values_clipped is not None else None,\n",
    "                           gridsize=demand_gridsize, cmap=demand_cmap, bins=None, mincnt=1,\n",
    "                           linewidths=0, alpha=0.92, zorder=5, norm=norm)\n",
    "            try:\n",
    "                hb.set_edgecolor('face')\n",
    "            except Exception:\n",
    "                pass\n",
    "            if show_colorbar and values is not None:\n",
    "                cbar = fig.colorbar(hb, ax=ax, shrink=0.8)\n",
    "                cbar.ax.tick_params(labelsize=10)\n",
    "    except Exception:\n",
    "        if show_heat:\n",
    "            sc = ax.scatter(ls[dx], ls[dy], c=ls[pop_col] if pop_col is not None else '#9ecae1',\n",
    "                            s=8, cmap=demand_cmap, edgecolors='none', zorder=5)\n",
    "            if show_colorbar and pop_col is not None:\n",
    "                fig.colorbar(sc, ax=ax, shrink=0.8)\n",
    "\n",
    "    if overlay_points:\n",
    "        try:\n",
    "            ax.scatter(ls[dx], ls[dy], s=overlay_points_size, c='#2c3e50', alpha=overlay_points_alpha,\n",
    "                       linewidths=0, zorder=6, label=LL['demand'])\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    legend_flag = {'selected': False, 'current': False}\n",
    "    for _, row in opt_sites.iterrows():\n",
    "        cx = float(row[x_col])\n",
    "        cy = float(row[y_col])\n",
    "        is_current = ('current' in opt_sites.columns and bool(row['current']) is True)\n",
    "        if is_current:\n",
    "            coll = ax.scatter(cx, cy, s=46, marker='o', facecolor='white', edgecolor='red', linewidths=1.2,\n",
    "                              zorder=10, label=LL['current'] if not legend_flag['current'] else None)\n",
    "            try:\n",
    "                coll.set_path_effects([pe.withStroke(linewidth=2.2, foreground='white')])\n",
    "            except Exception:\n",
    "                pass\n",
    "            legend_flag['current'] = True\n",
    "            circ_kwargs = dict(facecolor='none', edgecolor='red', lw=1.0, alpha=0.9, zorder=9)\n",
    "            if circle_style == 'fill':\n",
    "                circ_kwargs.update(facecolor='none')\n",
    "            ax.add_artist(plt.Circle((cx, cy), radius_m, **circ_kwargs))\n",
    "        else:\n",
    "            coll = ax.scatter(cx, cy, s=52, marker='o', facecolor='#FF8C42', edgecolor='white', linewidths=0.8,\n",
    "                              zorder=11, label=LL['selected'] if not legend_flag['selected'] else None)\n",
    "            try:\n",
    "                coll.set_path_effects([pe.withStroke(linewidth=2.0, foreground='white')])\n",
    "            except Exception:\n",
    "                pass\n",
    "            legend_flag['selected'] = True\n",
    "            if circle_style == 'fill':\n",
    "                circ = plt.Circle((cx, cy), radius_m, facecolor='#FF8C42', edgecolor='#FF8C42', lw=0.6, alpha=0.12, zorder=8)\n",
    "            else:\n",
    "                circ = plt.Circle((cx, cy), radius_m, facecolor='none', edgecolor='#FF8C42', lw=1.2, ls='--', alpha=0.85, zorder=9)\n",
    "            ax.add_artist(circ)\n",
    "\n",
    "    ax.axis('scaled')\n",
    "    ax.tick_params(axis='both', left=False, top=False, right=False,\n",
    "                   bottom=False, labelleft=False, labeltop=False,\n",
    "                   labelright=False, labelbottom=False)\n",
    "    ax.grid(False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(1.0)\n",
    "        spine.set_edgecolor('#333333')\n",
    "    ax.margins(x=0.02, y=0.02)\n",
    "\n",
    "    ttl = title if title is not None else LL['title']\n",
    "    ax.set_title(ttl + \"\\n\" + LL['subtitle'](len(opt_sites), int(radius_m)), fontsize=18, pad=12)\n",
    "    try:\n",
    "        render_scale_bar(ax=ax, x=0.05, y=0.05)\n",
    "        render_north_arrow(ax=ax, x=0.95, y=0.95, size=0.012, ratio=0.7)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    legend_marker_size = 8\n",
    "    has_current = ('current' in opt_sites.columns and bool(np.any(opt_sites['current'].astype(bool))))\n",
    "    custom_handles = []\n",
    "    # road\n",
    "    custom_handles.append(Line2D([0], [0], color=roads_color, lw=1.0, alpha=0.6, label=LL['road']))\n",
    "    # current (optional)\n",
    "    if has_current:\n",
    "        custom_handles.append(Line2D([0], [0], marker='o', color='none', markerfacecolor='white',\n",
    "                                     markeredgecolor='red', markeredgewidth=1.2, markersize=legend_marker_size,\n",
    "                                     label=LL['current']))\n",
    "    # demand\n",
    "    if overlay_points:\n",
    "        custom_handles.append(Line2D([0], [0], marker='o', color='none', markerfacecolor='#2c3e50',\n",
    "                                     markersize=legend_marker_size, alpha=overlay_points_alpha, label=LL['demand']))\n",
    "    # selected\n",
    "    if len(opt_sites) > 0:\n",
    "        custom_handles.append(Line2D([0], [0], marker='o', color='none', markerfacecolor='#FF8C42',\n",
    "                                     markeredgecolor='white', markeredgewidth=0.8, markersize=legend_marker_size,\n",
    "                                     label=LL['selected']))\n",
    "    ax.legend(handles=custom_handles, loc='lower right', markerscale=1.0, frameon=True, framealpha=0.85, fontsize=11)\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Demo call for pretty plot (Gurobi)\n",
    "try:\n",
    "    opt_sites = cand_df.loc[selected_sites]\n",
    "except Exception:\n",
    "    opt_sites = cand_df.iloc[:30]\n",
    "\n",
    "ax = plot_result_pretty(\n",
    "    ls_hlt,\n",
    "    opt_sites,\n",
    "    radius_m=1000,\n",
    "    roads_path=\"data/HuLaTang/Road_Network.shp\",\n",
    "    demand_gridsize=80,\n",
    "    demand_cmap=\"inferno\",\n",
    "    norm_mode=\"log\",\n",
    "    vmin_q=0.12,\n",
    "    vmax_q=0.995,\n",
    "    reduce=\"sum\",\n",
    "    circle_style=\"ring\",\n",
    "    show_heat=False,\n",
    "    lang=\"en\",\n",
    "    title=None\n",
    ")\n",
    "# 16:9 canvas (for PPT) and save HD image\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(20, 11.25)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"hulatang_result_pretty_SA.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T12:55:34.022754Z",
     "start_time": "2025-09-09T12:55:34.009753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print and save selected_sites (JSON only)\n",
    "import os, json\n",
    "\n",
    "try:\n",
    "    print(\"Gurobi selected site indices (selected_sites):\\n\", selected_sites)\n",
    "except NameError:\n",
    "    raise RuntimeError(\"'selected_sites' is undefined. Please run the solving cell first.\")\n",
    "\n",
    "# Save to results directory (JSON only)\n",
    "out_dir = \"results\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "json_path = os.path.join(out_dir, \"hulatang_gurobi_selected_sites.json\")\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"selected_sites\": selected_sites}, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved JSON:\", json_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpoNet-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
