{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:19.307136Z",
     "start_time": "2025-09-06T09:16:19.283495Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cooperative-Competitive Maximum Coverage Location Problem  solved by Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:19.506908Z",
     "start_time": "2025-09-06T09:16:19.494258Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Algorithm.GA_Hulatang import GeneticAlgorithm\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the real-world datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:19.677064Z",
     "start_time": "2025-09-06T09:16:19.663365Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Demand Population Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:19.984154Z",
     "start_time": "2025-09-06T09:16:19.787878Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ls = gpd.read_file(\"data/HuLaTang/Deman_Point.shp\")\n",
    "ls['POINT_X'] = ls.geometry.x\n",
    "ls['POINT_Y'] = ls.geometry.y\n",
    "all_pop_col = [c for c in ls.columns if c.lower()=='all_pop'][0]\n",
    "ls['speed_pct_freeflow_rev'] = ls[all_pop_col]\n",
    "ls.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:20.218065Z",
     "start_time": "2025-09-06T09:16:20.204497Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_to_1_10(data):\n",
    "    min_val = min(data)\n",
    "    max_val = max(data)\n",
    "    normalized_data = [(x - min_val) / (max_val - min_val) * 9 + 1 for x in data]\n",
    "    return normalized_data\n",
    "ls['speed_pct_freeflow_rev_norm'] = normalize_to_1_10(ls['speed_pct_freeflow_rev'])\n",
    "\n",
    "total_pop = sum(ls['speed_pct_freeflow_rev'])\n",
    "total_pop_norm = sum(ls['speed_pct_freeflow_rev_norm'])\n",
    "print(\"The number of records is \", len(ls))\n",
    "print(\"The total speed unit are \", total_pop)\n",
    "print(\"The total norm speed unit are \", total_pop_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:20.496232Z",
     "start_time": "2025-09-06T09:16:20.452734Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sitedf = pd.read_csv(\"data/HuLaTang/Candidate_Point.csv\", encoding='utf-8-sig')\n",
    "print(\"The number of candidate sites is \", len(sitedf))\n",
    "sitedf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:21.925869Z",
     "start_time": "2025-09-06T09:16:21.912847Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Normalization(x, y):\n",
    "    max_x, max_y = np.max(x), np.max(y)\n",
    "    min_x, min_y = np.min(x), np.min(y)\n",
    "    S_x = (max_x-min_x)\n",
    "    S_y = (max_y-min_y)\n",
    "    S = max(S_x, S_y)\n",
    "    new_x, new_y = (x-min_x)/S, (y-min_y)/S\n",
    "    data_xy = np.vstack((new_x, new_y))\n",
    "    Data = data_xy.T\n",
    "    return new_x, new_y, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:22.126953Z",
     "start_time": "2025-09-06T09:16:22.114810Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ls_X = np.array(ls['POINT_X'])\n",
    "ls_Y = np.array(ls['POINT_Y'])\n",
    "bbs_X = np.array(sitedf['point_x_1'] if 'point_x_1' in sitedf.columns else sitedf['POINT_X'])\n",
    "bbs_Y = np.array(sitedf['point_y_1'] if 'point_y_1' in sitedf.columns else sitedf['POINT_Y'])\n",
    "X = np.concatenate([ls_X, bbs_X])\n",
    "Y = np.concatenate([ls_Y, bbs_Y])\n",
    "NORM_X, NORM_Y, S = Normalization(X, Y)\n",
    "ls['NORM_X'] = NORM_X[:len(ls)]\n",
    "ls['NORM_Y'] = NORM_Y[:len(ls)]\n",
    "sitedf['NORM_X'] = NORM_X[len(ls):]\n",
    "sitedf['NORM_Y'] = NORM_Y[len(ls):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:22.587053Z",
     "start_time": "2025-09-06T09:16:22.374974Z"
    }
   },
   "outputs": [],
   "source": [
    "encodings = [\"utf-8-sig\", \"gbk\", \"utf-8\"]\n",
    "stores_df = None\n",
    "for enc in encodings:\n",
    "    try:\n",
    "        stores_df = pd.read_csv(\"data/HuLaTang/Hulatang.csv\", encoding=enc)\n",
    "        break\n",
    "    except Exception:\n",
    "        pass\n",
    "if stores_df is None:\n",
    "    raise RuntimeError(\"Failed to read Hulatang.csv\")\n",
    "\n",
    "store_x_col = None\n",
    "store_y_col = None\n",
    "for c in stores_df.columns:\n",
    "    if c.lower() in (\"x\", \"point_x\"): store_x_col = c\n",
    "    if c.lower() in (\"y\", \"point_y\"): store_y_col = c\n",
    "if store_x_col is None or store_y_col is None:\n",
    "    for c in stores_df.columns:\n",
    "        if c.lower() == \"point_x\": store_x_col = c\n",
    "        if c.lower() == \"point_y\": store_y_col = c\n",
    "if store_x_col is None or store_y_col is None:\n",
    "    raise ValueError(\"Store table is missing coordinate columns (X/Y or POINT_X/POINT_Y).\")\n",
    "\n",
    "Ak_col = None\n",
    "Pk_col = None\n",
    "for c in stores_df.columns:\n",
    "    if c.lower() == \"ak\": Ak_col = c\n",
    "    if c.lower() == \"pk\": Pk_col = c\n",
    "if Ak_col is None or Pk_col is None:\n",
    "    raise ValueError(\"Store table is missing Ak or Pk columns.\")\n",
    "\n",
    "cand_x_col = 'point_x_1' if 'point_x_1' in sitedf.columns else 'POINT_X'\n",
    "cand_y_col = 'point_y_1' if 'point_y_1' in sitedf.columns else 'POINT_Y'\n",
    "cand_xy = sitedf[[cand_x_col, cand_y_col]].to_numpy(float)\n",
    "store_xy = stores_df[[store_x_col, store_y_col]].to_numpy(float)\n",
    "\n",
    "all_xy = np.vstack([cand_xy, store_xy])\n",
    "min_x, max_x = all_xy[:,0].min(), all_xy[:,0].max()\n",
    "min_y, max_y = all_xy[:,1].min(), all_xy[:,1].max()\n",
    "S = max(max_x - min_x, max_y - min_y)\n",
    "\n",
    "cand_norm = (cand_xy - np.array([min_x, min_y])) / S\n",
    "store_norm = (store_xy - np.array([min_x, min_y])) / S\n",
    "\n",
    "sitedf['NORM_X'] = cand_norm[:,0]\n",
    "sitedf['NORM_Y'] = cand_norm[:,1]\n",
    "\n",
    "ls['NORM_X'] = (ls['POINT_X'] - min_x) / S\n",
    "ls['NORM_Y'] = (ls['POINT_Y'] - min_y) / S\n",
    "\n",
    "delta_agg = 700.0 / S\n",
    "delta_comp = 150.0 / S\n",
    "cd = cand_norm[:, None, :] - store_norm[None, :, :]\n",
    "dists_cs = np.sqrt((cd ** 2).sum(axis=2))\n",
    "B = (stores_df[Ak_col].to_numpy(float) * np.exp(- (dists_cs**2) / (delta_agg**2))).sum(axis=1)\n",
    "C = (stores_df[Pk_col].to_numpy(float) * np.exp(- (dists_cs**2) / (delta_comp**2))).sum(axis=1)\n",
    "\n",
    "rent_col = 'ZUJIN' if 'ZUJIN' in sitedf.columns else ('Zujin' if 'Zujin' in sitedf.columns else 'rent')\n",
    "rents = sitedf[rent_col].to_numpy(float)\n",
    "\n",
    "print(f\"Unified normalization done for candidates/stores, S={S:.3f}. Computed B/C and rent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:22.755943Z",
     "start_time": "2025-09-06T09:16:22.742931Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_candidate_sites(sites, M=100, heuristic = None):\n",
    "    '''\n",
    "    Generate M candidate sites with the convex hull of a point set\n",
    "    Input:\n",
    "        sites: a Pandas DataFrame with X, Y and other characteristic\n",
    "        M: the number of candidate sites to generate\n",
    "        heuristic:\n",
    "    Return:\n",
    "        sites: a Numpy array with shape of (M,2)\n",
    "    '''\n",
    "\n",
    "    if M is not None:\n",
    "        if M > len(sites):\n",
    "            M = None\n",
    "    if heuristic is None or heuristic == '':\n",
    "        if M is None:\n",
    "            return sites\n",
    "        np.random.seed(0)\n",
    "        index = np.random.choice(len(sites), M)\n",
    "        return sites.iloc[index]\n",
    "    elif heuristic == 'coverage':\n",
    "        sites = sites.sort_values(by='pop_covered_2km', ascending=False).reset_index()\n",
    "        if M is None:\n",
    "            return sites\n",
    "        return sites.iloc[:M]\n",
    "    elif heuristic == 'coverage_e':\n",
    "        sites = sites.sort_values(by='pop_covered_2km_exclusive', ascending=False).reset_index()\n",
    "        if M is None:\n",
    "            return sites\n",
    "        return sites.iloc[:M]\n",
    "    elif heuristic == 'impression':\n",
    "        sites = sites.sort_values(by='weeklyImpr', ascending=False).reset_index()\n",
    "        if M is None:\n",
    "            return sites\n",
    "        return sites.iloc[:M]\n",
    "    elif heuristic == 'impression_e':\n",
    "        sites = sites.sort_values(by='weeklyImpr_2km_exclusive', ascending=False).reset_index()\n",
    "        if M is None:\n",
    "            return sites\n",
    "        return sites.iloc[:M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:22.879189Z",
     "start_time": "2025-09-06T09:16:22.867189Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bbs_ = generate_candidate_sites(sitedf, M=None, heuristic=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:23.063410Z",
     "start_time": "2025-09-06T09:16:22.989312Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "users = np.array(ls[['NORM_X', 'NORM_Y']])\n",
    "facilities = np.array(bbs_[['NORM_X', 'NORM_Y']])\n",
    "demand = np.array(ls['speed_pct_freeflow_rev'])\n",
    "p = 20\n",
    "real_radius = 1000\n",
    "radius = real_radius/S\n",
    "\n",
    "dist = np.sum((facilities[:, np.newaxis, :] - users[np.newaxis, :, :]) ** 2, axis=-1) ** 0.5\n",
    "rent_col = 'ZUJIN' if 'ZUJIN' in bbs_.columns else ('Zujin' if 'Zujin' in bbs_.columns else 'rent')\n",
    "rents = np.array(bbs_[rent_col], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:26.089073Z",
     "start_time": "2025-09-06T09:16:23.204670Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "w1, w2, w3, w4 = 0.40, 0.20, 0.25, 0.15\n",
    "\n",
    "genetic = GeneticAlgorithm(\n",
    "    n=len(ls), m=len(bbs_), p=p,\n",
    "    cost_matrix=dist, r=radius,\n",
    "    demand=demand, costs=rents,\n",
    "    B=B, C=C,\n",
    "    w1=w1, w2=w2, w3=w3, w4=w4,\n",
    "    iterations=200, generation_size=80, reproduction_size=30, mutation_prob=0.1,\n",
    ")\n",
    "\n",
    "genetic.optimize()\n",
    "sol = genetic.get_solution_details()\n",
    "centers = sol['selected_facilities']\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Component metrics (aligned with Gurobi presentation)\n",
    "w1, w2, w3, w4 = 0.40, 0.20, 0.25, 0.15\n",
    "market_benefit = w1 * sol['covered_demand']\n",
    "agglomeration_benefit = w3 * sol['sum_B']\n",
    "competition_cost = w4 * sol['sum_C']\n",
    "rent_cost = w2 * sol['sum_rent']\n",
    "\n",
    "print(\"Selected facility indices:\", centers)\n",
    "print(\"Objective value:\", round(sol['objective_value']))\n",
    "print(\"Market coverage benefit:\", round(market_benefit))\n",
    "print(\"Agglomeration benefit:\", round(agglomeration_benefit))\n",
    "print(\"Competition cost:\", -round(competition_cost))  # negative for display\n",
    "print(\"Rent cost:\", -round(rent_cost))                # negative for display\n",
    "print(\"Average rent per facility:\", round(sol['sum_rent']/len(centers)) if len(centers)>0 else 0)\n",
    "print(\"Covered / Total demand:\", f\"{round(sol['covered_demand'])} / {round(sol['total_demand'])}\")\n",
    "print(\"Coverage rate:\", f\"{sol['coverage_rate']*100:.2f}%\")\n",
    "print(f\"Execution time: {execution_time:.2f}s\")\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:26.196557Z",
     "start_time": "2025-09-06T09:16:26.168748Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_result(ls, opt_sites, radius):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 12))\n",
    "\n",
    "    cmap = plt.cm.Blues\n",
    "    new_cmap = colors.ListedColormap(cmap(np.linspace(0.15, 1, 256)))\n",
    "    pop_col = None\n",
    "    if 'speed_pct_freeflow_rev' in ls.columns:\n",
    "        pop_col = 'speed_pct_freeflow_rev'\n",
    "    else:\n",
    "        for c in ls.columns:\n",
    "            if c.lower() == 'all_pop':\n",
    "                pop_col = c\n",
    "                break\n",
    "    try:\n",
    "        if pop_col is not None:\n",
    "            ls.plot(ax=ax, column=pop_col, k=5, markersize=5, cmap=new_cmap, label='Market')\n",
    "        else:\n",
    "            ls.plot(ax=ax, markersize=5, color='#8da0cb', label='Demand')\n",
    "    except Exception:\n",
    "        ls.plot(ax=ax, markersize=5, color='#8da0cb', label='Demand')\n",
    "\n",
    "    def pick_xy_cols(df):\n",
    "        x_col = None\n",
    "        y_col = None\n",
    "        for c in df.columns:\n",
    "            cl = str(c).lower()\n",
    "            if cl in ('point_x_1', 'x', 'point_x', 'pointx') and x_col is None:\n",
    "                x_col = c\n",
    "            if cl in ('point_y_1', 'y', 'point_y', 'pointy') and y_col is None:\n",
    "                y_col = c\n",
    "        if x_col is None and 'POINT_X' in df.columns: x_col = 'POINT_X'\n",
    "        if y_col is None and 'POINT_Y' in df.columns: y_col = 'POINT_Y'\n",
    "        if x_col is None or y_col is None:\n",
    "            raise ValueError('opt_sites is missing XY columns (point_x_1/point_y_1 or X/Y or POINT_X/POINT_Y).')\n",
    "        return x_col, y_col\n",
    "\n",
    "    x_col, y_col = pick_xy_cols(opt_sites)\n",
    "\n",
    "    legend_plot_flag = {'current': False, 'selected': False}\n",
    "    for _, site in opt_sites.iterrows():\n",
    "        cx = float(site[x_col])\n",
    "        cy = float(site[y_col])\n",
    "        if 'current' in opt_sites.columns and bool(site['current']) is True:\n",
    "            if legend_plot_flag['current'] is False:\n",
    "                ax.scatter(cx, cy, c='red', marker='+', s=10, label='Current Sites')\n",
    "                legend_plot_flag['current'] = True\n",
    "            ax.scatter(cx, cy, c='red', marker='+', s=100)\n",
    "            circle = plt.Circle((cx, cy), radius, color='red', fill=False, lw=2)\n",
    "            ax.add_artist(circle)\n",
    "        else:\n",
    "            if legend_plot_flag['selected'] is False:\n",
    "                ax.scatter(cx, cy, c='C1', marker='+', s=10, label='Optimized Selected Sites')\n",
    "                legend_plot_flag['selected'] = True\n",
    "            ax.scatter(cx, cy, c='C1', marker='+', s=100)\n",
    "            # circle = plt.Circle((cx, cy), radius, color='C1', fill=False, lw=2)\n",
    "            # ax.add_artist(circle)\n",
    "\n",
    "    ax.axis('scaled')\n",
    "    ax.tick_params(axis='both', left=False, top=False, right=False,\n",
    "                   bottom=False, labelleft=False, labeltop=False,\n",
    "                   labelright=False, labelbottom=False)\n",
    "    ax.set_title('Selected {} Sites that Serve {} m'.format(len(opt_sites), radius), fontsize=20)\n",
    "    render_scale_bar(ax=ax, x=0.05, y=0.05)\n",
    "    render_north_arrow(ax=ax, x=0.95, y=0.95, size=0.01, ratio=0.7)\n",
    "    ax.legend(loc='lower right', markerscale=10)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:26.290001Z",
     "start_time": "2025-09-06T09:16:26.276656Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def render_scale_bar(ax, x, y, segments=2, height=0.01, seg_length=2000, unit='m', linewidth=1.):\n",
    "    unit_scale_factor = {\n",
    "        'm': 1,\n",
    "        'km': 1000,\n",
    "        'meters': 1,\n",
    "        'kilometers': 1000,\n",
    "        'miles': 1609.34,\n",
    "        'mi': 1609.34,\n",
    "        'ft': 0.3,\n",
    "        }\n",
    "    x_lim = ax.get_xlim()\n",
    "    y_lim = ax.get_ylim()\n",
    "\n",
    "    # how much percent does one unit takes on the x axis\n",
    "    x_per_unit = 1. / (x_lim[1] - x_lim[0])\n",
    "    y_per_unit = 1. / (y_lim[1] - y_lim[0])\n",
    "\n",
    "    # base for ticks (0, 1)\n",
    "    x_base = [x + seg_length * unit_scale_factor[unit] * x_per_unit * i for i in range(0, segments + 1)]\n",
    "    ax.axhline(y_lim[0] + y / y_per_unit, x_base[0], x_base[-1], c='black')\n",
    "    y_base = [y, y + height]\n",
    "    for i in range(segments + 1):\n",
    "        ax.axvline(x_lim[0] + x_base[i] / x_per_unit, y, y + height, c='black')\n",
    "        xy = (x_lim[0] + x_base[i] / x_per_unit, y_lim[0] + (y - 0.015) / y_per_unit)  # data_coords\n",
    "        ax.text(xy[0], xy[1], s='{}'.format(int(seg_length * i)), horizontalalignment='center', verticalalignment='center')\n",
    "    ax.text(x_lim[0] + (x_base[-1] + 0.02) / x_per_unit, y_lim[0] + (y - 0.015) / y_per_unit,\n",
    "            s=unit, horizontalalignment='left',\n",
    "            verticalalignment='center')\n",
    "def render_north_arrow(ax, x, y, size, ratio = 1):\n",
    "    path = [(0, 1), (-ratio, -1), (0, -0.5), (ratio, -1), (0, 1)]\n",
    "    path = [(i[0] * size + x, i[1] * size + y) for i in path]\n",
    "    arrow = plt.Polygon(path, color='black', transform=ax.transAxes)\n",
    "    ax.add_patch(arrow)\n",
    "    ax.text(x, y-size*2, s = 'N', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:26.751882Z",
     "start_time": "2025-09-06T09:16:26.383284Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt_sites = bbs_.iloc[centers]\n",
    "plot_result(ls,opt_sites,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:26.874948Z",
     "start_time": "2025-09-06T09:16:26.862447Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:27.028925Z",
     "start_time": "2025-09-06T09:16:26.984631Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_result_pretty(ls, opt_sites, radius_m=2000, roads_path=\"data/HuLaTang/Road_Network.shp\",\n",
    "                       demand_gridsize=60, demand_cmap=\"magma\", roads_color=\"#9e9e9e\",\n",
    "                       norm_mode=\"log\", vmin_q=0.10, vmax_q=0.995, gamma=0.6, reduce=\"sum\",\n",
    "                       overlay_points=True, overlay_points_size=6, overlay_points_alpha=0.28,\n",
    "                       overlay_hex_grid=False, hex_grid_color=\"#222222\", hex_grid_alpha=0.18, hex_grid_lw=0.25):\n",
    "    pop_col = None\n",
    "    if 'speed_pct_freeflow_rev' in ls.columns:\n",
    "        pop_col = 'speed_pct_freeflow_rev'\n",
    "    else:\n",
    "        for c in ls.columns:\n",
    "            if str(c).lower() == 'all_pop':\n",
    "                pop_col = c\n",
    "                break\n",
    "    if 'X' in ls.columns and 'Y' in ls.columns:\n",
    "        dx, dy = 'X', 'Y'\n",
    "    else:\n",
    "        dx, dy = 'POINT_X', 'POINT_Y'\n",
    "    if dx not in ls.columns or dy not in ls.columns:\n",
    "        raise ValueError(\"ls must contain POINT_X/POINT_Y or X/Y columns.\")\n",
    "\n",
    "    def pick_xy_cols(df):\n",
    "        x_col = None\n",
    "        y_col = None\n",
    "        for c in df.columns:\n",
    "            cl = str(c).lower()\n",
    "            if cl in ('point_x_1', 'x', 'point_x', 'pointx') and x_col is None:\n",
    "                x_col = c\n",
    "            if cl in ('point_y_1', 'y', 'point_y', 'pointy') and y_col is None:\n",
    "                y_col = c\n",
    "        if x_col is None and 'POINT_X' in df.columns: x_col = 'POINT_X'\n",
    "        if y_col is None and 'POINT_Y' in df.columns: y_col = 'POINT_Y'\n",
    "        if x_col is None or y_col is None:\n",
    "            raise ValueError('opt_sites missing XY columns (point_x_1/point_y_1 or X/Y or POINT_X/POINT_Y).')\n",
    "        return x_col, y_col\n",
    "\n",
    "    x_col, y_col = pick_xy_cols(opt_sites)\n",
    "\n",
    "    # 3) Figure\n",
    "    fig, ax = plt.subplots(figsize=(20, 16))\n",
    "\n",
    "    # Roads overlay at bottom\n",
    "    if isinstance(roads_path, str) and os.path.exists(roads_path):\n",
    "        try:\n",
    "            roads = gpd.read_file(roads_path)\n",
    "            try:\n",
    "                roads.plot(ax=ax, color=roads_color, linewidth=0.3, alpha=0.35, zorder=1, label='Road network')\n",
    "            except Exception:\n",
    "                pass\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Demand heat via hexbin (no gaps) with normalization and quantile clipping (plot-only)\n",
    "    try:\n",
    "        values = ls[pop_col].to_numpy() if pop_col is not None else None\n",
    "        if values is not None:\n",
    "            vmin = float(np.quantile(values, vmin_q)) if 0 <= vmin_q < 1 else None\n",
    "            vmax = float(np.quantile(values, vmax_q)) if 0 < vmax_q <= 1 else None\n",
    "            if vmin is not None and vmax is not None and vmax > vmin:\n",
    "                values_clipped = np.clip(values, vmin, vmax)\n",
    "            else:\n",
    "                values_clipped = values\n",
    "            norm = None\n",
    "            if norm_mode == 'log':\n",
    "                from matplotlib.colors import LogNorm\n",
    "                norm = LogNorm(vmin=max(values_clipped.min(), 1e-6), vmax=values_clipped.max())\n",
    "            elif norm_mode == 'power':\n",
    "                from matplotlib.colors import PowerNorm\n",
    "                norm = PowerNorm(gamma=gamma, vmin=values_clipped.min(), vmax=values_clipped.max())\n",
    "            else:\n",
    "                norm = None\n",
    "        else:\n",
    "            values_clipped = None\n",
    "            norm = None\n",
    "\n",
    "        reducer = np.sum if reduce == 'sum' else np.mean\n",
    "        hb = ax.hexbin(ls[dx].to_numpy(), ls[dy].to_numpy(),\n",
    "                       C=values_clipped,\n",
    "                       reduce_C_function=reducer if values_clipped is not None else None,\n",
    "                       gridsize=demand_gridsize, cmap=demand_cmap, bins=None, mincnt=1,\n",
    "                       linewidths=0, alpha=0.95, zorder=5, norm=norm)\n",
    "        try:\n",
    "            hb.set_edgecolor('face')\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Remove colorbar to keep the figure clean (optional)\n",
    "        # cbar = fig.colorbar(hb, ax=ax, shrink=0.8)\n",
    "        # cbar.set_label('Demand intensity', fontsize=12)\n",
    "    except Exception:\n",
    "        sc = ax.scatter(ls[dx], ls[dy], c=ls[pop_col] if pop_col is not None else '#9ecae1',\n",
    "                        s=8, cmap=demand_cmap, edgecolors='none', zorder=5)\n",
    "        if pop_col is not None:\n",
    "            # Remove colorbar (optional)\n",
    "            # cbar = fig.colorbar(sc, ax=ax, shrink=0.8)\n",
    "            # cbar.set_label('Demand intensity', fontsize=12)\n",
    "            pass\n",
    "\n",
    "    # Optional overlay: demand points and hex grid\n",
    "    # Hex grid overlay is disabled by default\n",
    "    # if overlay_hex_grid:\n",
    "    #     try:\n",
    "    #         hb_grid = ax.hexbin(ls[dx].to_numpy(), ls[dy].to_numpy(),\n",
    "    #                             gridsize=demand_gridsize, C=None, reduce_C_function=None,\n",
    "    #                             linewidths=hex_grid_lw, edgecolors=hex_grid_color, facecolors='none',\n",
    "    #                             alpha=hex_grid_alpha, zorder=4)\n",
    "    #     except Exception:\n",
    "    #         pass\n",
    "    if overlay_points:\n",
    "        try:\n",
    "            ax.scatter(ls[dx], ls[dy], s=overlay_points_size, c='#000000', alpha=overlay_points_alpha,\n",
    "                       linewidths=0, zorder=6, label='Demand points')\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Facilities and service circles\n",
    "    legend_flag = {'selected': False, 'current': False}\n",
    "    for _, row in opt_sites.iterrows():\n",
    "        cx = float(row[x_col])\n",
    "        cy = float(row[y_col])\n",
    "        is_current = ('current' in opt_sites.columns and bool(row['current']) is True)\n",
    "        if is_current:\n",
    "            if not legend_flag['current']:\n",
    "                ax.scatter(cx, cy, s=40, marker='o', facecolor='white', edgecolor='red', linewidths=1.2,\n",
    "                           label='Current sites', zorder=9)\n",
    "                legend_flag['current'] = True\n",
    "            else:\n",
    "                ax.scatter(cx, cy, s=40, marker='o', facecolor='white', edgecolor='red', linewidths=1.2, zorder=9)\n",
    "            circ = plt.Circle((cx, cy), radius_m, facecolor='none', edgecolor='red', lw=0.9, alpha=0.9, zorder=8)\n",
    "            ax.add_artist(circ)\n",
    "        else:\n",
    "            if not legend_flag['selected']:\n",
    "                ax.scatter(cx, cy, s=44, marker='o', facecolor='C1', edgecolor='white', linewidths=0.6,\n",
    "                           label='Selected facilities', zorder=10)\n",
    "                legend_flag['selected'] = True\n",
    "            else:\n",
    "                ax.scatter(cx, cy, s=44, marker='o', facecolor='C1', edgecolor='white', linewidths=0.6, zorder=10)\n",
    "            circ = plt.Circle((cx, cy), radius_m, facecolor='C1', edgecolor='C1', lw=0.6, alpha=0.12, zorder=8)\n",
    "            ax.add_artist(circ)\n",
    "\n",
    "    # Aesthetics\n",
    "    ax.axis('scaled')\n",
    "    ax.tick_params(axis='both', left=False, top=False, right=False,\n",
    "                   bottom=False, labelleft=False, labeltop=False,\n",
    "                   labelright=False, labelbottom=False)\n",
    "    ax.grid(False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(0.8)\n",
    "        spine.set_edgecolor('#444444')\n",
    "    ax.set_title('Optimized Facility Locations with Demand Heat and Roads', fontsize=18)\n",
    "    try:\n",
    "        render_scale_bar(ax=ax, x=0.05, y=0.05)\n",
    "        render_north_arrow(ax=ax, x=0.95, y=0.95, size=0.01, ratio=0.7)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Compose custom legend entries to ensure demand points and roads appear\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if not any(lbl == 'Demand points' for lbl in labels):\n",
    "        handles.append(Line2D([0], [0], marker='o', color='none', markerfacecolor='#000000',\n",
    "                              markersize=6, alpha=overlay_points_alpha, label='Demand points'))\n",
    "    if not any(lbl == 'Road network' for lbl in labels):\n",
    "        handles.append(Line2D([0], [0], color=roads_color, lw=1.0, alpha=0.6, label='Road network'))\n",
    "    ax.legend(handles=handles, loc='lower right', markerscale=1.6, frameon=True, framealpha=0.9)\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:30.598282Z",
     "start_time": "2025-09-06T09:16:27.122534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demo call for pretty plot (GA)\n",
    "try:\n",
    "    opt_sites = bbs_.iloc[centers]\n",
    "except Exception:\n",
    "    # fallback: if centers not defined, skip\n",
    "    opt_sites = bbs_.iloc[:30]\n",
    "\n",
    "ax = plot_result_pretty(ls, opt_sites, radius_m=1000, roads_path=\"data/HuLaTang/Road_Network.shp\",\n",
    "                        demand_gridsize=80, demand_cmap=\"inferno\", norm_mode=\"log\", vmin_q=0.10, vmax_q=0.995,\n",
    "                        reduce=\"sum\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:31.263416Z",
     "start_time": "2025-09-06T09:16:30.721968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Result figure: demand hexbin gradient + road overlay + facility points\n",
    "# - Roads: overlay if a GeoDataFrame variable exists or if data/roads.(geojson|shp) is available\n",
    "# - Demand intensity: weighted sum within hexagons if provided; auto-switch linear/log normalization\n",
    "# - Axes: hide axes and ticks; keep only the colorbar\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path\n",
    "\n",
    "# Try importing GeoPandas for road plotting\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    _has_gpd = True\n",
    "except Exception:\n",
    "    _has_gpd = False\n",
    "\n",
    "# Guess common variable names (ordered by priority)\n",
    "possible_demand_xy = [\n",
    "    ('demand_x', 'demand_y'),\n",
    "    ('X', 'Y'),\n",
    "    ('clients_x', 'clients_y'),\n",
    "    ('demand_points_x', 'demand_points_y'),\n",
    "    ('dx', 'dy'),\n",
    "]\n",
    "possible_demand_strength = ['demand_w', 'weights', 'w', 'demand_strength', 'demands']\n",
    "possible_facility_xy = [\n",
    "    ('facility_x', 'facility_y'),\n",
    "    ('fac_x', 'fac_y'),\n",
    "    ('selected_facility_x', 'selected_facility_y'),\n",
    "    ('sites_x', 'sites_y'),\n",
    "    ('best_x', 'best_y'),\n",
    "]\n",
    "possible_roads_vars = ['roads_gdf', 'roads', 'edges_gdf', 'edges', 'road_gdf', 'G_edges', 'gdf_edges']\n",
    "possible_roads_files = [\n",
    "    'data/roads.geojson', 'data/roads.shp', 'data/road.geojson', 'data/road.shp',\n",
    "    'data/roads/roads.shp', 'data/osm_roads.geojson'\n",
    "]\n",
    "\n",
    "# Manual fallback (if auto-detection fails, provide variables above and disable auto-detection)\n",
    "# demand_x, demand_y = your_demand_x_array, your_demand_y_array\n",
    "# demand_w = your_demand_weight_array  # optional, same length as demand_x/demand_y\n",
    "# facility_x, facility_y = your_facility_x_array, your_facility_y_array\n",
    "# roads_gdf = gpd.read_file('your_roads_file.geojson')\n",
    "\n",
    "locals_dict = globals()\n",
    "\n",
    "\n",
    "def get_first_existing_pair(candidates):\n",
    "    for a, b in candidates:\n",
    "        if a in locals_dict and b in locals_dict:\n",
    "            ax = np.asarray(locals_dict[a]).ravel()\n",
    "            ay = np.asarray(locals_dict[b]).ravel()\n",
    "            if ax.size and ay.size and ax.size == ay.size:\n",
    "                return ax, ay\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def get_first_existing_array(candidates):\n",
    "    for k in candidates:\n",
    "        if k in locals_dict:\n",
    "            arr = np.asarray(locals_dict[k]).ravel()\n",
    "            if arr.size:\n",
    "                return arr\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_first_existing_roads():\n",
    "    if not _has_gpd:\n",
    "        return None\n",
    "    # Prefer variables first\n",
    "    for k in possible_roads_vars:\n",
    "        if k in locals_dict:\n",
    "            obj = locals_dict[k]\n",
    "            if isinstance(obj, gpd.GeoDataFrame) and len(obj) > 0:\n",
    "                return obj\n",
    "    # Fallback to files\n",
    "    for rel in possible_roads_files:\n",
    "        p = Path(rel)\n",
    "        if p.exists():\n",
    "            try:\n",
    "                gdf = gpd.read_file(p)\n",
    "                if len(gdf) > 0:\n",
    "                    return gdf\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "\n",
    "# Get demand coordinates/strength, facilities, and roads\n",
    "cx, cy = get_first_existing_pair(possible_demand_xy)\n",
    "cw = get_first_existing_array(possible_demand_strength)\n",
    "fx, fy = get_first_existing_pair(possible_facility_xy)\n",
    "roads_gdf = get_first_existing_roads()\n",
    "\n",
    "if cx is None or cy is None:\n",
    "    raise RuntimeError('Failed to auto-detect demand coordinate variables. Please provide demand_x/demand_y.')\n",
    "\n",
    "# Colormap: brighter high values\n",
    "cmap = mpl.cm.get_cmap('YlOrRd')\n",
    "\n",
    "# Weight switch & normalization: log for positive wide-range values, otherwise linear\n",
    "use_weight = cw is not None and cw.shape[0] == cx.shape[0]\n",
    "norm = None\n",
    "if use_weight:\n",
    "    cw = np.asarray(cw).astype(float)\n",
    "    cw = np.where(np.isfinite(cw), cw, 0.0)\n",
    "    cw = np.clip(cw, a_min=0.0, a_max=None)\n",
    "    pos = cw[cw > 0]\n",
    "    if pos.size:\n",
    "        vmin = np.percentile(pos, 2)\n",
    "        vmax = np.percentile(pos, 98)\n",
    "        vmax = max(vmax, vmin * 1.01)\n",
    "        dynamic = (vmax / max(vmin, 1e-9))\n",
    "        if dynamic >= 50:\n",
    "            norm = mpl.colors.LogNorm(vmin=max(vmin, 1e-6), vmax=vmax)\n",
    "        else:\n",
    "            norm = mpl.colors.Normalize(vmin=0, vmax=vmax)\n",
    "    else:\n",
    "        norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(9, 8), dpi=150)\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# 1) Roads (bottom layer)\n",
    "if roads_gdf is not None:\n",
    "    try:\n",
    "        roads_gdf.plot(ax=ax, color=(0, 0, 0, 0.12), linewidth=0.6, zorder=1)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# 2) Demand hexbin (middle layer)\n",
    "hex_kwargs = {\n",
    "    'gridsize': 50,                 # grid density\n",
    "    'cmap': cmap,\n",
    "    'linewidths': 0.3,\n",
    "    'edgecolors': (1, 1, 1, 0.6),   # semi-transparent white edges\n",
    "    'mincnt': 1,                    # color only when at least one point exists\n",
    "    'zorder': 2,\n",
    "}\n",
    "\n",
    "if use_weight:\n",
    "    hb = ax.hexbin(cx, cy, C=cw, reduce_C_function=np.sum, norm=norm, **hex_kwargs)\n",
    "    cbar = fig.colorbar(hb, ax=ax)\n",
    "    cbar.set_label('Demand intensity (weighted sum within hexagon)', fontsize=10)\n",
    "else:\n",
    "    # Count only; use log scale to reveal low values for large datasets\n",
    "    hb = ax.hexbin(cx, cy, norm=mpl.colors.LogNorm() if len(cx) > 2000 else None, **hex_kwargs)\n",
    "    cbar = fig.colorbar(hb, ax=ax)\n",
    "    cbar.set_label('Number of demand points', fontsize=10)\n",
    "\n",
    "# 3) Facilities (top layer)\n",
    "if fx is not None and fy is not None:\n",
    "    ax.scatter(fx, fy, s=40, c='#ff7f0e', marker='o', edgecolors='k', linewidths=0.6, zorder=3, label='Selected facilities')\n",
    "    ax.legend(loc='lower right', fontsize=9, frameon=True, framealpha=0.6)\n",
    "\n",
    "# Layout: remove axes and ticks; keep colorbar\n",
    "ax.set_axis_off()\n",
    "ax.set_aspect('equal', adjustable='datalim')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save (optional)\n",
    "# fig.savefig('results/final_hexbin_with_roads.png', dpi=220, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T09:16:35.031834Z",
     "start_time": "2025-09-06T09:16:31.376918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Raw data visualization (without selected facilities overlay)\n",
    "# Show only demand heat and roads, do not show facilities\n",
    "try:\n",
    "    opt_sites_empty = bbs_.iloc[0:0]\n",
    "except Exception:\n",
    "    opt_sites_empty = sitedf.iloc[0:0]\n",
    "\n",
    "ax = plot_result_pretty(\n",
    "    ls,\n",
    "    opt_sites_empty,\n",
    "    radius_m=1000,\n",
    "    roads_path=\"data/HuLaTang/Road_Network.shp\",\n",
    "    demand_gridsize=80,\n",
    "    demand_cmap=\"inferno\",\n",
    "    norm_mode=\"log\",\n",
    "    vmin_q=0.10,\n",
    "    vmax_q=0.995,\n",
    "    reduce=\"sum\",\n",
    "    overlay_points=True\n",
    ")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpoNet-master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
